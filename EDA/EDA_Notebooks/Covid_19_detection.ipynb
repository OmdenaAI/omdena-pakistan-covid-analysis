{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0036cf3e",
   "metadata": {},
   "source": [
    "## Covid 19 Prediction\n",
    "### By Doaa Ahmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf3413",
   "metadata": {},
   "source": [
    "### Intorduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb442778",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cca4366f",
   "metadata": {},
   "source": [
    "* [Step 0](#step0): Import Dataset\n",
    "* [Step 1](#step1): Split the data set\n",
    "* [Step 2](#step2): Creat Data Loaders\n",
    "* [Step 3](#step3): Creat Train Function\n",
    "* [Step 4](#step4): Create Test Function\n",
    "* [Step 5](#step5): Creat VGG Model\n",
    "* [Step 6](#step6): Set Hyper Parameters\n",
    "* [Step 7](#step7): Train The model\n",
    "* [Step 8](#step8): Test The model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d55376",
   "metadata": {},
   "source": [
    "<a id='step0'></a>\n",
    "## Step 0: Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819402f",
   "metadata": {},
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a18a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 745 total  images, with covid-19 and non covid-19 cases\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load filenames for all images\n",
    "all_files = np.array(glob(\"./images/*/*\"))\n",
    "\n",
    "\n",
    "# print number of images in the dataset\n",
    "print('There are %d total  images, with covid-19 and non covid-19 cases' % len(all_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77977a5",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Split the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a8f16",
   "metadata": {},
   "source": [
    "Here I have splitted the available data into test(10%), train(80%) and validation(10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e411a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying files: 0 files [00:00, ? files/s]\u001b[A\n",
      "Copying files: 12 files [00:00, 117.88 files/s]\u001b[A\n",
      "Copying files: 40 files [00:00, 209.27 files/s]\u001b[A\n",
      "Copying files: 65 files [00:00, 224.87 files/s]\u001b[A\n",
      "Copying files: 91 files [00:00, 237.82 files/s]\u001b[A\n",
      "Copying files: 117 files [00:00, 244.24 files/s]\u001b[A\n",
      "Copying files: 142 files [00:00, 237.63 files/s]\u001b[A\n",
      "Copying files: 166 files [00:00, 229.16 files/s]\u001b[A\n",
      "Copying files: 189 files [00:00, 223.52 files/s]\u001b[A\n",
      "Copying files: 219 files [00:00, 245.64 files/s]\u001b[A\n",
      "Copying files: 245 files [00:01, 249.37 files/s]\u001b[A\n",
      "Copying files: 275 files [00:01, 262.31 files/s]\u001b[A\n",
      "Copying files: 302 files [00:01, 260.18 files/s]\u001b[A\n",
      "Copying files: 329 files [00:01, 250.76 files/s]\u001b[A\n",
      "Copying files: 355 files [00:01, 188.90 files/s]\u001b[A\n",
      "Copying files: 378 files [00:01, 196.78 files/s]\u001b[A\n",
      "Copying files: 400 files [00:01, 196.35 files/s]\u001b[A\n",
      "Copying files: 425 files [00:01, 208.63 files/s]\u001b[A\n",
      "Copying files: 448 files [00:02, 212.78 files/s]\u001b[A\n",
      "Copying files: 471 files [00:02, 212.41 files/s]\u001b[A\n",
      "Copying files: 494 files [00:02, 215.65 files/s]\u001b[A\n",
      "Copying files: 520 files [00:02, 227.70 files/s]\u001b[A\n",
      "Copying files: 552 files [00:02, 253.63 files/s]\u001b[A\n",
      "Copying files: 580 files [00:02, 260.72 files/s]\u001b[A\n",
      "Copying files: 607 files [00:02, 252.55 files/s]\u001b[A\n",
      "Copying files: 636 files [00:02, 261.23 files/s]\u001b[A\n",
      "Copying files: 666 files [00:02, 269.52 files/s]\u001b[A\n",
      "Copying files: 694 files [00:02, 263.65 files/s]\u001b[A\n",
      "Copying files: 745 files [00:03, 238.04 files/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "data_dir = './images'\n",
    "splitfolders.ratio(data_dir, output=\"./splitted_Data\", seed=1337, ratio=(.8, 0.1,0.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbdd87",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Creat Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac13fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 110 files [03:17,  1.79s/ files] \n",
      "Copying files: 32 files [04:47,  9.00s/ files]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_COVID', 'CT_NonCOVID']\n",
      "Number of avaialable classes:  2\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "#batch size\n",
    "batch_size = 20\n",
    "\n",
    "#convert the data to a normalized tensor\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "    transforms.RandomVerticalFlip(),                                       \n",
    "    #transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "    transforms.Normalize((0.5,0.5,0.5) , (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    transforms.Normalize((0.5,0.5,0.5) , (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "data_dir = 'splitted_Data/'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "valid_dir = os.path.join(data_dir, 'val/')\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=train_transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "#prepare a dict for all loaders\n",
    "loaders ={}\n",
    "loaders['train'] = train_loader\n",
    "loaders['test'] = test_loader\n",
    "loaders['valid'] = valid_loader\n",
    "\n",
    "# get available classes, to be used as the output\n",
    "classes = []\n",
    "for cl in train_data.classes:\n",
    "    classes.append(cl)\n",
    "print(classes)\n",
    "\n",
    "print(\"Number of avaialable classes: \" , len(classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b36ac",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Create Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad34ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training function\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    \n",
    "    #load previous model if it exists, to save time\n",
    "    if os.path.exists(save_path):\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    #valid_loss_min = 0.469987\n",
    "        \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            #clear optimizer\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            #compute predicted op\n",
    "            output = model(data)\n",
    "        \n",
    "            #calculate error/loss for this batch\n",
    "            loss = criterion(output, target)   \n",
    "            loss.backward()        \n",
    "            optimizer.step()\n",
    "            ## record the average training loss\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            #train_loss += loss.item() * data.size(0) #multiply by batch size\n",
    "            \n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            #in validation we don't do backward propagation\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            #valid_loss += loss.item()* data.size(0)\n",
    "\n",
    "        #train_loss = train_loss / len(loaders['train'].dataset)\n",
    "        #valid_loss = valid_loss / len(loaders['valid'].dataset)\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print(\"validation loss decreased {:.6f} --> {:.6f} . saving model .. \".format(valid_loss_min, valid_loss))\n",
    "            torch.save(model.state_dict() , save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719272a",
   "metadata": {},
   "source": [
    "<a id='step4'></a>\n",
    "## Step 4: Creat Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c23bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62790276",
   "metadata": {},
   "source": [
    "<a id='step5'></a>\n",
    "## Step 5: Creat VGG Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf06cb5",
   "metadata": {},
   "source": [
    "#### Creating the pre-trained model, VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75f40c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "output after replacing last layer: \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Load the pretrained model from pytorch\n",
    "model_VGG = models.vgg16(pretrained=True)\n",
    "\n",
    "# print out the model structure\n",
    "print(model_VGG)\n",
    "\n",
    "for param in model_VGG.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "    \n",
    "n_inputs = model_VGG.classifier[6].in_features\n",
    "\n",
    "# add last linear layer (n_inputs ->ECG classes)\n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "\n",
    "model_VGG.classifier[6] = last_layer\n",
    "\n",
    "# check to see that your last layer produces the expected number of outputs\n",
    "print(\"output after replacing last layer: \")\n",
    "print(model_VGG.classifier[6].out_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bffe3ea",
   "metadata": {},
   "source": [
    "<a id='step6'></a>\n",
    "## Step 6: Set Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82a2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "n_epochs =20\n",
    "learning_rate = 0.01\n",
    "criterion_VGG = nn.CrossEntropyLoss()\n",
    "optimizer_VGG = optim.SGD(model_VGG.classifier.parameters(), lr=learning_rate )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_VGG = model_VGG.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30339f2",
   "metadata": {},
   "source": [
    "<a id='step7'></a>\n",
    "## Step 7: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "341b3f00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.700715 \tValidation Loss: 0.767886\n",
      "validation loss decreased inf --> 0.767886 . saving model .. \n",
      "Epoch: 2 \tTraining Loss: 0.592961 \tValidation Loss: 0.460362\n",
      "validation loss decreased 0.767886 --> 0.460362 . saving model .. \n",
      "Epoch: 3 \tTraining Loss: 0.461054 \tValidation Loss: 0.467876\n",
      "Epoch: 4 \tTraining Loss: 0.460571 \tValidation Loss: 0.483861\n",
      "Epoch: 5 \tTraining Loss: 0.396237 \tValidation Loss: 0.486898\n",
      "Epoch: 6 \tTraining Loss: 0.366191 \tValidation Loss: 0.374951\n",
      "validation loss decreased 0.460362 --> 0.374951 . saving model .. \n",
      "Epoch: 7 \tTraining Loss: 0.314143 \tValidation Loss: 0.484454\n",
      "Epoch: 8 \tTraining Loss: 0.320894 \tValidation Loss: 0.420726\n",
      "Epoch: 9 \tTraining Loss: 0.276895 \tValidation Loss: 0.411589\n",
      "Epoch: 10 \tTraining Loss: 0.275061 \tValidation Loss: 0.480977\n",
      "Epoch: 11 \tTraining Loss: 0.247887 \tValidation Loss: 0.411246\n",
      "Epoch: 12 \tTraining Loss: 0.192193 \tValidation Loss: 0.465228\n",
      "Epoch: 13 \tTraining Loss: 0.202929 \tValidation Loss: 0.458640\n",
      "Epoch: 14 \tTraining Loss: 0.183228 \tValidation Loss: 0.440305\n",
      "Epoch: 15 \tTraining Loss: 0.150102 \tValidation Loss: 0.452874\n",
      "Epoch: 16 \tTraining Loss: 0.162308 \tValidation Loss: 0.438956\n",
      "Epoch: 17 \tTraining Loss: 0.126290 \tValidation Loss: 0.402819\n",
      "Epoch: 18 \tTraining Loss: 0.113386 \tValidation Loss: 0.520672\n",
      "Epoch: 19 \tTraining Loss: 0.106292 \tValidation Loss: 0.521567\n",
      "Epoch: 20 \tTraining Loss: 0.118711 \tValidation Loss: 0.568916\n"
     ]
    }
   ],
   "source": [
    "model_VGG = train(n_epochs, loaders, model_VGG, optimizer_VGG, criterion_VGG, use_cuda, 'model_VGG_Covid19_1.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779cde2",
   "metadata": {},
   "source": [
    "<a id='step8'></a>\n",
    "## Step 8: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "971a4ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy \n",
    "model_VGG.load_state_dict(torch.load('model_VGG_Covid19_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d24930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.440860\n",
      "\n",
      "\n",
      "Test Accuracy: 83% (64/77)\n"
     ]
    }
   ],
   "source": [
    "test(loaders, model_VGG, criterion_VGG, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212e242",
   "metadata": {},
   "source": [
    "### Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d60fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
